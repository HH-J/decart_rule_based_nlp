{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from IPython.display import SVG\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to spaCy\n",
    "We'll finish up our course by looking at `spaCy`, a great Python library for working with natural language processing. While most of the tools we've used so far have been rule-based, spaCy consists mostly of **statistical NLP** models. In statistical models, a large corpus of text is processed and mathematical methods are used to identify patterns in the corpus. This process is called **training**. Once a model has been trained, we can use it to analyze new text. \n",
    "\n",
    "spaCy comes with several pre-trained models, meaning that we can quickly load a model which has been trained on large amounts of data. This way, we can take advantage of work which has already been done by spaCy developers and focus on our own NLP tasks. In these notebooks, we'll see how combining spaCy's statistical models with rule-based systems offers a powerful way to process and analyze text.\n",
    "\n",
    "## What we'll do today\n",
    "\n",
    "We'll start by looking at the basic usage of spaCy. Next, we'll focus on specific NLP task, **named entity recognition (NER)**, and see how this works in spaCy, as well as some of the limitations with clinical data. Some of these limitations can be addressed by writing our own rules for concept extraction, and we'll practice that with some clinical texts. We'll then go a little deeper into how spaCy's models are implemented and how we can modify them. Finally, we'll end the day by spaCy models which were designed specifically for use in the biomedical domain.\n",
    "\n",
    "# spaCy documentation\n",
    "\n",
    "spaCy has great documentation. As we're going along today, try browsing through their documentation to find examples and instructions. Start by opening up these two pages and navigating through the documentation:\n",
    "\n",
    "[Basic spaCy usage](https://spacy.io/usage/models)\n",
    "\n",
    "[API documentation](https://spacy.io/api)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage of spaCy\n",
    "\n",
    "\n",
    "In this notebook, we'll look at the basic fundamentals of spaCy:\n",
    "- Main classes in spaCy\n",
    "- Linguistic attributes available as part of default text processing\n",
    "- Coding exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use spaCy\n",
    "At a high-level, here are the steps for using spaCy:\n",
    "- Start by loading a pre-trained NLP model\n",
    "- Process a string of text with the model\n",
    "- Use the attributes in our processed documents for downstream NLP tasks like NER or document classification\n",
    "\n",
    "For example, here's a very short example of how this works. For the sake of demonstration, we'll use this snippet of a recent, exciting news article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load a pre-trained model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Taco Bell’s latest marketing venture, a pop-up hotel, opened at 10 a.m. Pacific Time Thursday. \n",
       "The rooms sold out within two minutes.\n",
       "The resort has been called “The Bell: A Taco Bell Hotel and Resort.” It’s located in Palm Springs, California."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process a string of text with the model\n",
    "text = \"\"\"Taco Bell’s latest marketing venture, a pop-up hotel, opened at 10 a.m. Pacific Time Thursday. \n",
    "The rooms sold out within two minutes.\n",
    "The resort has been called “The Bell: A Taco Bell Hotel and Resort.” It’s located in Palm Springs, California.\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Taco Bell’s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " latest marketing venture, a pop-up hotel, opened at \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    10 a.m.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Pacific Time\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Thursday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". </br>The rooms sold out within \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    two minutes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       ".</br>The resort has been called “\n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    The Bell:\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " A Taco Bell Hotel and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Resort\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".” It’s located in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Palm Springs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    California\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the attributes in our processed documents for downstream NLP tasks\n",
    "# Here, we'll visualize the entities in this text identified through NER\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dive a little deeper into how spaCy is structured and what we have to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy architecture\n",
    "The following diagram from spaCy's API documentation shows a basic overview of spaCy's architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"o-svg\" height=\"746\" viewBox=\"-1 -1 907 737\" width=\"906\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "    <style>\n",
       "        .svg__architecture__text-large, .svg__architecture__text-medium, .svg__architecture__text-small {\n",
       "            font-family: Arial, sans-serif;\n",
       "            fill: #1a1e23\n",
       "        }\n",
       "        .svg__architecture__text-large { font-size: 18px; font-weight: bold }\n",
       "        .svg__architecture__text-medium { font-size: 15px }\n",
       "        .svg__architecture__text-small { font-size: 14px; font-weight: bold }\n",
       "        .svg__architecture__text-code {  font: 600 12px Menlo, Monaco, Consolas, &quot;Liberation Mono&quot;, &quot;Courier New&quot;, monospace }\n",
       "    </style>\n",
       "    <ellipse cx=\"404\" cy=\"203\" fill=\"#dae8fc\" rx=\"74.8\" ry=\"49.8\" stroke=\"#09a3d5\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-large\" height=\"40\" transform=\"translate(362.5 206.5)\" width=\"81\">Language</text>\n",
       "    <path d=\"M345 432v242.8\" fill=\"none\" stroke=\"#82b366\" stroke-dasharray=\"2 2\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M345 680.8l-4-8 4 2 4-2z\" fill=\"#82b366\" stroke=\"#82b366\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#fff\" height=\"18\" transform=\"translate(324 535.5)\" width=\"37\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"1em\" height=\"18\" style=\"fill: #82b366\" transform=\"translate(324 535.5)\" width=\"37\">MAKES</text>\n",
       "    <path d=\"M457 434l100.5 80\" fill=\"none\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M562.3 517.6l-8.8-1.8 4-2 1-4.3z\" fill=\"#999\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#f6f6f6\" height=\"18\" transform=\"translate(424.5 462.5)\" width=\"158\"/>\n",
       "    <text class=\"svg__architecture__text-code\" dx=\"0.4em\" dy=\"1em\" height=\"18\" transform=\"translate(424.5 462.5)\" width=\"158\">nlp.vocab.morphology</text>\n",
       "    <ellipse cx=\"404\" cy=\"399\" fill=\"#d5e8d4\" rx=\"74.8\" ry=\"49.8\" stroke=\"#82b366\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-large\" dy=\"1em\" height=\"22\" transform=\"translate(377.5 386.5)\" width=\"51\">Vocab</text>\n",
       "    <path d=\"M404 253v87.8\" fill=\"none\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M404 346.8l-4-8 4 2 4-2z\" fill=\"#999\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#f6f6f6\" height=\"18\" transform=\"translate(364.5 285.5)\" width=\"79\"/>\n",
       "    <text class=\"svg__architecture__text-code\" dx=\"0.4em\" dy=\"1em\" height=\"18\" transform=\"translate(364.5 285.5)\" width=\"79\">nlp.vocab</text>\n",
       "    <ellipse cx=\"743\" cy=\"399\" fill=\"#f5f5f5\" rx=\"74.8\" ry=\"49.8\" stroke=\"#666\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-large\" dy=\"1em\" height=\"22\" transform=\"translate(694.5 386.5)\" width=\"95\">StringStore</text>\n",
       "    <path d=\"M478 399h181.8\" fill=\"none\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M665.8 399l-8 4 2-4-2-4z\" fill=\"#999\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#f6f6f6\" height=\"18\" transform=\"translate(498.5 388.5)\" width=\"137\"/>\n",
       "    <text class=\"svg__architecture__text-code\" dx=\"0.4em\" dy=\"1em\" height=\"18\" transform=\"translate(498.5 388.5)\" width=\"137\">nlp.vocab.strings</text>\n",
       "    <path d=\"M108 244l235.6 115.4\" fill=\"none\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M349 362h-9l3.6-2.6V355z\" fill=\"#999\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#f6f6f6\" height=\"18\" transform=\"translate(141.5 284.5)\" width=\"151\"/>\n",
       "    <text class=\"svg__architecture__text-code\" dx=\"0.4em\" dy=\"1em\" height=\"18\" transform=\"translate(141.5 284.5)\" width=\"151\">nlp.tokenizer.vocab</text>\n",
       "    <path d=\"M38.7 159.3H104l33 43.6-32.8 43.5H38.7L6 203z\" fill=\"#f8cecc\" stroke=\"#b85450\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-large\" dy=\"1em\" height=\"22\" transform=\"translate(30.5 190.5)\" width=\"80\">Tokenizer</text>\n",
       "    <path d=\"M329 203v-1H145.2\" fill=\"none\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M139.2 202l8-4-2 4 2 4z\" fill=\"#999\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#f6f6f6\" height=\"18\" transform=\"translate(188.5 191.5)\" width=\"115\"/>\n",
       "    <text class=\"svg__architecture__text-code\" dx=\"0.4em\" dy=\"1em\" height=\"18\" transform=\"translate(188.5 191.5)\" width=\"115\">nlp.make_doc()</text>\n",
       "    <path d=\"M478 203h83v-4h105.8\" fill=\"none\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M672.8 199l-8 4 2-4-2-4z\" fill=\"#999\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#f6f6f6\" height=\"18\" transform=\"translate(512.5 191.5)\" width=\"101\"/>\n",
       "    <text class=\"svg__architecture__text-code\" dx=\"0.4em\" dy=\"1em\" height=\"18\" transform=\"translate(512.5 191.5)\" width=\"101\">nlp.pipeline</text>\n",
       "    <path d=\"M709 242.8L464.4 359.4\" fill=\"none\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M459 362l5.5-7v4.4l3.5 2.8z\" fill=\"#999\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#f6f6f6\" height=\"18\" transform=\"translate(505.5 297.5)\" width=\"166\"/>\n",
       "    <text class=\"svg__architecture__text-code\" dx=\"0.4em\" dy=\"1em\" height=\"18\" transform=\"translate(505.5 297.5)\" width=\"166\">nlp.pipeline[i].vocab</text>\n",
       "    <path d=\"M275.3 34.6L288.6 1h54L329 34.6z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(301.5 9.5)\" width=\"12\">pt</text>\n",
       "    <path d=\"M60.8 34.6L74.3 1h54l-13.6 33.6z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(86.5 9.5)\" width=\"14\">en</text>\n",
       "    <path d=\"M114.4 34.6L128 1h53.8l-13.5 33.6z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(140.5 9.5)\" width=\"14\">de</text>\n",
       "    <path d=\"M168 34.6L181.5 1h54l-13.6 33.6z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(196.5 9.5)\" width=\"8\">fr</text>\n",
       "    <path d=\"M221.6 34.6L235 1h54l-13.5 33.6z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(248.5 9.5)\" width=\"12\">es</text>\n",
       "    <path d=\"M47 68.3l13.6-33.6h53.8L101 68.3z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(75.5 43.5)\" width=\"8\">it</text>\n",
       "    <path d=\"M100.7 68.3l13.5-33.6H168l-13.4 33.6z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(127.5 43.5)\" width=\"12\">nl</text>\n",
       "    <path d=\"M154.3 68.3l13.5-33.6h53.8l-13.4 33.6z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(180.5 43.5)\" width=\"12\">sv</text>\n",
       "    <path d=\"M208 68.3l13.4-33.6h53.8L262 68.3z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(236.5 43.5)\" width=\"8\">fi</text>\n",
       "    <path d=\"M261.5 68.3L275 34.7h54l-13.6 33.6z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(286.5 43.5)\" width=\"16\">nb</text>\n",
       "    <path d=\"M33.4 102L47 68.2h53.7L87.3 102z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(58.5 77.5)\" width=\"16\">hu</text>\n",
       "    <path d=\"M87 102l13.5-33.7h53.8L141 102z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(112.5 77.5)\" width=\"14\">he</text>\n",
       "    <path d=\"M140.6 102L154 68.2h54L194.4 102z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(165.5 77.5)\" width=\"16\">bn</text>\n",
       "    <path d=\"M194.2 102l13.5-33.7h53.8L248 102z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(221.5 77.5)\" width=\"10\">ja</text>\n",
       "    <path d=\"M247.8 102l13.5-33.7H315L301.8 102z\" fill=\"#dae8fc\" stroke=\"#6c8ebf\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dy=\"0.85em\" height=\"14\" transform=\"translate(273.5 77.5)\" width=\"14\">...</text>\n",
       "    <path d=\"M329 51h75v93.8\" fill=\"none\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M404 150.8l-4-8 4 2 4-2z\" fill=\"#999\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M213 480l109.3-76.3\" fill=\"none\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M327.2 400.3L323 408l-.8-4.3-4-2z\" fill=\"#999\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#f6f6f6\" height=\"18\" transform=\"translate(226.5 431.5)\" width=\"79\"/>\n",
       "    <text class=\"svg__architecture__text-code\" dx=\"0.4em\" dy=\"1em\" height=\"18\" transform=\"translate(226.5 431.5)\" width=\"79\">doc.vocab</text>\n",
       "    <path d=\"M39.6 555.5l.4 121.3\" fill=\"none\" stroke=\"#9673a6\" stroke-dasharray=\"2 2\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M40 682.8l-4-8 4 2 4-2z\" fill=\"#9673a6\" stroke=\"#9673a6\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#fff\" height=\"18\" transform=\"translate(23.5 604.5)\" width=\"37\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dx=\"-0.5em\" dy=\"1em\" height=\"18\" style=\"fill: #9673a6\" transform=\"translate(23.5 604.5)\" width=\"37\">MAKES</text>\n",
       "    <path d=\"M1 479.5h283v74.8H1z\" fill=\"#e1d5e7\" stroke=\"#9673a6\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-large\" dy=\"1em\" height=\"22\" transform=\"translate(125.5 504.5)\" width=\"32\">Doc</text>\n",
       "    <path d=\"M71 246v117h1v108.8\" fill=\"none\" stroke=\"#c00\" stroke-dasharray=\"2 2\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M72 477.8l-4-8 4 2 4-2z\" fill=\"#c00\" stroke=\"#c00\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#fff\" height=\"18\" transform=\"translate(54.5 355.5)\" width=\"37\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dx=\"-0.5em\" dy=\"1em\" height=\"18\" style=\"fill: #cc0000\" transform=\"translate(54.5 355.5)\" width=\"37\">MAKES</text>\n",
       "    <path d=\"M104 685l.4-121.2\" fill=\"none\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M104.5 557.8l4 8-4-2-4 2z\" fill=\"#999\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#f6f6f6\" height=\"18\" transform=\"translate(62.5 632.5)\" width=\"79\"/>\n",
       "    <text class=\"svg__architecture__text-code\" dx=\"0.4em\" dy=\"1em\" height=\"18\" transform=\"translate(62.5 632.5)\" width=\"79\">token.doc</text>\n",
       "    <path d=\"M7.2 685h129.6v50H7.2z\" fill=\"#f5f5f5\" stroke=\"#666\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-medium\" dy=\"1em\" height=\"18\" transform=\"translate(49.5 700.5)\" width=\"43\">Token</text>\n",
       "    <path d=\"M148 685h129.7v50H148z\" fill=\"#f5f5f5\" stroke=\"#666\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-medium\" dy=\"1em\" height=\"18\" transform=\"translate(193.5 700.5)\" width=\"37\">Span</text>\n",
       "    <path d=\"M405 686V456.6\" fill=\"none\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M405 450.6l4 8-4-2-4 2z\" fill=\"#999\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#f6f6f6\" height=\"18\" transform=\"translate(356.5 584.5)\" width=\"101\"/>\n",
       "    <text class=\"svg__architecture__text-code\" dx=\"0.4em\" dy=\"1em\" height=\"18\" transform=\"translate(356.5 584.5)\" width=\"101\">lexeme.vocab</text>\n",
       "    <path d=\"M296.7 685h155.8v50H296.7z\" fill=\"#f5f5f5\" stroke=\"#666\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-medium\" dy=\"1em\" height=\"18\" transform=\"translate(346.5 700.5)\" width=\"55\">Lexeme</text>\n",
       "    <path d=\"M180.5 559.3l.5 117.5\" fill=\"none\" stroke=\"#9673a6\" stroke-dasharray=\"2 2\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M181 682.8l-4-8 4 2 4-2z\" fill=\"#9673a6\" stroke=\"#9673a6\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#fff\" height=\"18\" transform=\"translate(164.5 606.5)\" width=\"37\"/>\n",
       "    <text class=\"svg__architecture__text-small\" dx=\"-0.5em\" dy=\"1em\" height=\"18\" style=\"fill: #9673a6\" transform=\"translate(164.5 606.5)\" width=\"37\">MAKES</text>\n",
       "    <path d=\"M245.3 685V564\" fill=\"none\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <path d=\"M245.3 557.8l4 8-4-2-4 2z\" fill=\"#999\" stroke=\"#999\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <rect fill=\"#f6f6f6\" height=\"18\" transform=\"translate(211.5 633.5)\" width=\"72\"/>\n",
       "    <text class=\"svg__architecture__text-code\" dx=\"0.4em\" dy=\"1em\" height=\"18\" transform=\"translate(211.5 633.5)\" width=\"72\">span.doc</text>\n",
       "    <path d=\"M806.6 112H872l32.8 43.5L872 199h-65.4L774 155.6z\" fill=\"#ffe6cc\" stroke=\"#d79b00\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-medium\" dy=\"1em\" height=\"38\" transform=\"translate(794.5 135.5)\" width=\"88\">Dependency <tspan dx=\"-4.1em\" dy=\"1.25em\">Parser</tspan></text>\n",
       "    <path d=\"M806.6 199H872l32.8 43.8-32.8 43.6h-65.4L774 242.8z\" fill=\"#ffe6cc\" stroke=\"#d79b00\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-medium\" dx=\"1.1em\" dy=\"1em\" height=\"38\" transform=\"translate(799.5 222.5)\" width=\"78\">Entity <tspan dx=\"-3.75em\" dy=\"1.25em\">Recognizer</tspan></text>\n",
       "    <path d=\"M708 155.5h65.6l32.7 43.6-32.7 43.8H708L675.5 199z\" fill=\"#ffe6cc\" stroke=\"#d79b00\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-medium\" dy=\"1em\" height=\"18\" transform=\"translate(715.5 189.5)\" width=\"48\">Tagger</text>\n",
       "    <path d=\"M806.8 24.5h65.5L905 68 872.3 112h-65.5L774 68z\" fill=\"#ffe6cc\" stroke=\"#d79b00\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-medium\" dy=\"1em\" height=\"18\" transform=\"translate(815 50)\" width=\"58\">Custom <tspan dx=\"-4.8em\" dy=\"1.25em\">Components</tspan></text>\n",
       "    <path d=\"M708.6 68H774l32.8 43.5L774 155h-65.4L676 111.6z\" fill=\"#ffe6cc\" stroke=\"#d79b00\" stroke-miterlimit=\"10\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-medium\" dy=\"1em\" height=\"18\" transform=\"translate(690 101.5)\" width=\"84\">TextCategorizer</text>\n",
       "    <ellipse cx=\"617\" cy=\"555\" fill=\"#f5f5f5\" rx=\"74.8\" ry=\"49.8\" stroke=\"#666\" stroke-width=\"2\"/>\n",
       "    <text class=\"svg__architecture__text-large\" dy=\"1em\" height=\"22\" transform=\"translate(565.5 542.5)\" width=\"101\">Morphology</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG('./images/spacy_architecture.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of information in this diagram, so we'll start small by focusing on these 4 spaCy classes:\n",
    "- `Language`: The NLP model used to process text\n",
    "- `Doc`: A sequence of text which has been processed by a `Language` object\n",
    "- `Token`: A single word or symbol in a Doc\n",
    "- `Span`: A slice from a Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Language` class\n",
    "The `nlp` object in spaCy is the linguistic model which will be used for processing text. We instantiate a `Language` class by providing the name of a pre-trained model which we wish to use. We typically name this object `nlp`, and this will be our primary entry point.\n",
    "\n",
    "\n",
    "Statistical, pre-trained, explain more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f2ba5faae80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nlp` model we instantiated above is a **small** (\"sm\"), **English** (\"en\")-language model trained on **web** (\"web\") data, but there are currently 16 different models from 9 different languages. See the [spaCy documentation](https://spacy.io/usage/models) for more information on each of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents, spans and tokens\n",
    "The `nlp` object is what we'll be using to process text. The next few classes represent the output of our NLP model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Doc` class\n",
    "The `doc` object represents a single document of text. To create a `doc` object, we call `nlp` on a string of text. This runs that text through a spaCy pipeline, which we'll learn more about in a future notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Taco Bell’s latest marketing venture, a pop-up hotel, opened at 10 a.m. Pacific Time Thursday.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taco Bell’s latest marketing venture, a pop-up hotel, opened at 10 a.m. Pacific Time Thursday.\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens and Spans\n",
    "A `Token` is a single word, symbol, or whitespace in a `doc`. When we create a `doc` object, the text broken up into individual tokens. This is called **\"tokenization\"**.\n",
    "\n",
    "**Discussion**: Look at the tokens generated from this text snippet. What can you say about the tokenization method? Is it as simple as splitting up into words every time we reach a whitespace?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Taco"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taco\n",
      "Bell\n",
      "’s\n",
      "latest\n",
      "marketing\n",
      "venture\n",
      ",\n",
      "a\n",
      "pop\n",
      "-\n",
      "up\n",
      "hotel\n",
      ",\n",
      "opened\n",
      "at\n",
      "10\n",
      "a.m.\n",
      "Pacific\n",
      "Time\n",
      "Thursday\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Span` is a slice of a document, or a consecutive sequence of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = doc[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bell’s latest"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linguistic Attributes\n",
    "Because spaCy comes with pre-trained linguistic models, when we call `nlp` on a text we have access to a number of linguistic attributes in the `doc` or `token` objects:\n",
    "\n",
    "- Part-of-speech (POS) tagging\n",
    "- Morphology\n",
    "- Dependency Parsing\n",
    "- Named entity recognition\n",
    "- Sentence splitting\n",
    "- Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "Parts of speech are categories of words. For example, \"nouns\", \"verbs\", and \"adjectives\" are all examples of parts of speech. Assigning parts of speech to words is useful for downstream NLP texts such as word sense disambiguation and named entity recognition.\n",
    "\n",
    "**Discussion**: What to the POS tags below mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token -> POS\n",
      "\n",
      "Taco -> PROPN\n",
      "Bell -> PROPN\n",
      "’s -> PROPN\n",
      "latest -> ADJ\n",
      "marketing -> NOUN\n",
      "venture -> NOUN\n",
      ", -> PUNCT\n",
      "a -> DET\n",
      "pop -> NOUN\n",
      "- -> PUNCT\n",
      "up -> PART\n",
      "hotel -> NOUN\n",
      ", -> PUNCT\n",
      "opened -> VERB\n",
      "at -> ADP\n",
      "10 -> NUM\n",
      "a.m. -> NOUN\n",
      "Pacific -> PROPN\n",
      "Time -> PROPN\n",
      "Thursday -> PROPN\n",
      ". -> PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token -> POS\\n\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} -> {token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"PROPN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morphology\n",
    "The morphology of a word refers to the form of a word. For example, \"eat\", \"eats\", and \"ate\" are all different inflections of the word \"eat\". We would say that \"eat\" is the **lemma** of all of these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token -> Lemma\n",
      "\n",
      "Taco -> Taco\n",
      "Bell -> Bell\n",
      "’s -> ’s\n",
      "latest -> late\n",
      "marketing -> marketing\n",
      "venture -> venture\n",
      ", -> ,\n",
      "a -> a\n",
      "pop -> pop\n",
      "- -> -\n",
      "up -> up\n",
      "hotel -> hotel\n",
      ", -> ,\n",
      "opened -> open\n",
      "at -> at\n",
      "10 -> 10\n",
      "a.m. -> a.m.\n",
      "Pacific -> Pacific\n",
      "Time -> Time\n",
      "Thursday -> Thursday\n",
      ". -> .\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token -> Lemma\\n\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} -> {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Parsing\n",
    "In dependency parsing, we analyze the structure of a sentence. We won't spend too much time on this, but here is a nice visualization of dependency parse looks like. Take a minute to look at the arrows between words and try to figure out what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The cat sat on the green mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"d27b4f9f17f04eafb0b62e9aac385463-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">cat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">sat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">green</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">mat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d27b4f9f17f04eafb0b62e9aac385463-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d27b4f9f17f04eafb0b62e9aac385463-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d27b4f9f17f04eafb0b62e9aac385463-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d27b4f9f17f04eafb0b62e9aac385463-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d27b4f9f17f04eafb0b62e9aac385463-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d27b4f9f17f04eafb0b62e9aac385463-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d27b4f9f17f04eafb0b62e9aac385463-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d27b4f9f17f04eafb0b62e9aac385463-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d27b4f9f17f04eafb0b62e9aac385463-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d27b4f9f17f04eafb0b62e9aac385463-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d27b4f9f17f04eafb0b62e9aac385463-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d27b4f9f17f04eafb0b62e9aac385463-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,266.5 L1108.0,254.5 1092.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other attributes\n",
    "Look at spaCy's [Token class documentation](https://spacy.io/api/token) for a full list of additional attributes available for each token in a document. We'll print out a few more.\n",
    "\n",
    "**Discussion**: How can these attributes be useful in downstream NLP tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Bitcoin rose 7.9% to $11,899 as of 11:53 a.m. in New York on Monday. \"\n",
    "    \"https://www.bloomberg.com/news/articles/2019-07-08/bitcoin-breakout-may-be-ahead-as-technicals-show-rally-extension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin rose 7.9% to $11,899 as of 11:53 a.m. in New York on Monday. https://www.bloomberg.com/news/articles/2019-07-08/bitcoin-breakout-may-be-ahead-as-technicals-show-rally-extension\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"shape\" of the token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin\n",
      "Xxxxx\n"
     ]
    }
   ],
   "source": [
    "print(doc[0])\n",
    "print(doc[0].shape_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector of a token (we'll learn more about this in the upcoming [statistical NLP class](https://datascience4health.bmi.utah.edu/statistical-nlp/) )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.2791505 , -3.6231017 , -4.038311  ,  1.621927  ,  0.33003563,\n",
       "       -0.36835814, -1.1787496 , -0.9574218 , -2.3754406 , -2.1553    ,\n",
       "        2.015212  ,  3.8695936 , -3.4196744 , -0.59352744, -1.4212173 ,\n",
       "       -2.6224658 , -0.18970647,  0.37852868,  4.6692142 ,  1.710747  ,\n",
       "        1.1691847 , -2.792294  ,  2.933097  ,  4.125014  , -0.6041511 ,\n",
       "        3.328246  ,  0.03704858, -4.797726  ,  1.6109418 ,  4.148142  ,\n",
       "        4.0968904 , -1.550179  , -1.1174474 , -4.7082205 , -1.8186622 ,\n",
       "       -4.225642  ,  5.0690312 ,  2.8283648 , -3.0518012 ,  2.710712  ,\n",
       "       -1.4477763 , -0.95311993, -3.5241623 ,  1.0967116 , -2.4924178 ,\n",
       "       -2.7999656 ,  1.5899887 , -3.786115  ,  2.8625512 , -2.3767047 ,\n",
       "       -0.02440187, -2.2565053 , -4.7382507 , -1.1424143 ,  2.7950048 ,\n",
       "        0.06551647, -2.5569944 ,  2.6399126 , -2.249659  , -2.1926837 ,\n",
       "       -4.9000244 , -2.991856  ,  0.2683387 ,  2.889857  , -2.7990513 ,\n",
       "       -1.7907519 ,  2.505558  , -3.400581  ,  0.03229642, -4.1048913 ,\n",
       "        4.957878  , -1.3145993 ,  6.1637926 ,  0.8831321 ,  1.5375423 ,\n",
       "        2.8873549 ,  0.48950583, -1.2065314 ,  1.1561632 , -0.26440954,\n",
       "       -6.9068136 ,  5.820908  ,  1.4617364 , -0.7537426 ,  3.9383776 ,\n",
       "        7.403804  ,  3.0109131 , -1.8104887 ,  0.25699666,  1.3684305 ,\n",
       "        3.6261523 ,  0.8456804 ,  3.0125155 ,  7.587589  ,  0.6927687 ,\n",
       "       -2.4028473 ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether the token resembles a:\n",
    "- Number\n",
    "- Punctuation\n",
    "- Currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.9\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(doc[2])\n",
    "print(doc[2].like_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(doc[5])\n",
    "print(doc[5].is_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bloomberg.com/news/articles/2019-07-08/bitcoin-breakout-may-be-ahead-as-technicals-show-rally-extension\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(doc[-1])\n",
    "print(doc[-1].like_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Exercises and Discussions\n",
    "Now that we've seen some examples of what we can do with spaCy, let's practice with some coding exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Ambiguity** \n",
    "\n",
    "Consider these two sentences and look at the word \"duck\". Consider these questions and discuss them with a group:\n",
    "- Are the two tokens \"duck\" in these two sentences identical? What does that tell us about a \"token\" vs. a normal string?\n",
    "- When two words are spelled the same but have different meanings, they are \"ambiguous\". Using spaCy, what are some ways we we could \"disambiguate\" the word \"duck\" in these two sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"The duck swam gently down the river.\")\n",
    "doc2 = nlp(\"He had to duck as he came through the door.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck1 = doc1[1]\n",
    "duck2 = doc2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duck1 == duck2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Count POS tags** \n",
    "\n",
    "Write a function that takes a Doc and returns a count of the number of each POS tag in that doc.\n",
    "\n",
    "*Bonus*: Write a second function that plots a bar graph of these counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def count_pos_tags(doc):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    d = defaultdict(int)\n",
    "    for token in doc:\n",
    "        d[token.pos_] += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"The highly vivacious green paint is giving me a terrible, mind-splitting headache.\")\n",
    "doc2 = nlp(\"My favorite activites are swimming, biking, reading, eating, and watching trashy shows on Netflix.\")\n",
    "doc3 = nlp(\"On Tuesday, the 28 EU leaders chose Ursula von der Leyen, an ally of German Chancellor Angela Merkel, \"\n",
    "            \"to replace Jean-Claude Juncker at the helm of the Commission.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = (doc1, doc2, doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'DET': 2, 'ADV': 1, 'ADJ': 3, 'NOUN': 4, 'VERB': 2, 'PRON': 1, 'PUNCT': 3})\n",
      "defaultdict(<class 'int'>, {'DET': 1, 'ADJ': 2, 'NOUN': 2, 'VERB': 6, 'PUNCT': 5, 'CCONJ': 1, 'ADP': 1, 'PROPN': 1})\n",
      "defaultdict(<class 'int'>, {'ADP': 4, 'PROPN': 12, 'PUNCT': 5, 'DET': 4, 'NUM': 1, 'NOUN': 4, 'VERB': 2, 'ADJ': 1, 'PART': 1})\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(count_pos_tags(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Sort by number of words with a certain POS tag**\n",
    "\n",
    "Write a function that takes a list of Docs and a POS tag. Return a new list which is sorted in **descending order** by the number of tokens which have that POS tag. Use a default value of 'PROPN' for the argument `pos_tag`. Test this out using the list `docs` from the last exercise.\n",
    "\n",
    "**Hint**: Use the built-in [sorted function](https://www.geeksforgeeks.org/sorted-function-python/) to sort the list, and use a lambda function to define the key which we should sort by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_pos(docs, pos_tag):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    srtd_docs = sorted(docs, key=lambda doc: count_pos_tag(doc, pos_tag), reverse=True)\n",
    "    return srtd_docs\n",
    "    \n",
    "def count_pos_tag(doc, pos_tag):\n",
    "    n = 0\n",
    "    for token in doc:\n",
    "        if token.pos_ == pos_tag:\n",
    "            n += 1\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[On Tuesday, the 28 EU leaders chose Ursula von der Leyen, an ally of German Chancellor Angela Merkel, to replace Jean-Claude Juncker at the helm of the Commission.,\n",
       " My favorite activites are swimming, biking, reading, eating, and watching trashy shows on Netflix.,\n",
       " The highly vivacious green paint is giving me a terrible, mind-splitting headache.]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by which documents have the most proper nouns\n",
    "sort_by_pos(docs, 'PROPN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[My favorite activites are swimming, biking, reading, eating, and watching trashy shows on Netflix.,\n",
       " The highly vivacious green paint is giving me a terrible, mind-splitting headache.,\n",
       " On Tuesday, the 28 EU leaders chose Ursula von der Leyen, an ally of German Chancellor Angela Merkel, to replace Jean-Claude Juncker at the helm of the Commission.]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by which documents have the most verbs\n",
    "sort_by_pos(docs, 'VERB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[The highly vivacious green paint is giving me a terrible, mind-splitting headache.,\n",
       " My favorite activites are swimming, biking, reading, eating, and watching trashy shows on Netflix.,\n",
       " On Tuesday, the 28 EU leaders chose Ursula von der Leyen, an ally of German Chancellor Angela Merkel, to replace Jean-Claude Juncker at the helm of the Commission.]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by which documents have the most adjectives\n",
    "sort_by_pos(docs, 'ADJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
